{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import pickle\n",
    "import os\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 4,
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lgb(X_fit, y_fit, X_val, y_val, counter, lgb_path, name):\n",
    "    \n",
    "    model = lgb.LGBMClassifier(max_depth=-1,\n",
    "                               n_estimators=999999,\n",
    "                               learning_rate=0.1,\n",
    "                               colsample_bytree=0.79,\n",
    "                               num_leaves=2,\n",
    "                               metric='auc',\n",
    "                               objective='binary', \n",
    "                               n_jobs=-1,\n",
<<<<<<< HEAD
    "                               verbose=2)\n",
    "    \n",
    "#  {'target': -0.8888258488813868, 'params': {'bagging_fraction': 0.951163427814695, \n",
    "#                                             'feature_fraction': 0.9450348885475112, \n",
    "#                                             'lambda_l1': 0.24642982155987636, \n",
    "#                                             'max_depth': 9.865442205008463, \n",
    "#                                             'min_data_in_leaf': 46.341585013143494, \n",
    "#                                             'num_leaves': 127.87400737010466}}\n",
=======
    "                              verbose=2)\n",
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
    "     \n",
    "    model.fit(X_fit, y_fit, \n",
    "              eval_set=[(X_val, y_val)],\n",
    "              verbose=0, \n",
    "              early_stopping_rounds=1000)\n",
    "                  \n",
    "    cv_val = model.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    #Save LightGBM Model\n",
    "    save_to = '{}{}_fold{}.txt'.format(lgb_path, name, counter+1)\n",
    "    model.booster_.save_model(save_to)\n",
    "    \n",
    "    return cv_val"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 5,
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_cb(X_fit, y_fit, X_val, y_val, counter, cb_path, name):\n",
    "    \n",
    "    model = cb.CatBoostClassifier(iterations=999999,\n",
    "                                  max_depth=2,\n",
    "                                  bagging_temperature=0.9795867288127285,\n",
    "                                  border_count=255,\n",
    "                                  l2_leaf_reg=30,\n",
    "                                  random_strength=3.1798317949397603,\n",
    "                                  learning_rate=0.12872771895424406,\n",
    "                                  colsample_bylevel=0.03,\n",
    "                                  objective=\"Logloss\",\n",
    "                                  verbose=10)                           \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "                                  \n",
    "    model.fit(X_fit, y_fit, \n",
    "              eval_set=[(X_val, y_val)], \n",
    "              verbose=0, early_stopping_rounds=1000)\n",
    "              \n",
    "    cv_val = model.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    #Save Catboost Model          \n",
    "    save_to = \"{}{}_fold{}.mlmodel\".format(cb_path, name, counter+1)\n",
    "    model.save_model(save_to, format=\"coreml\", \n",
    "                     export_parameters={'prediction_type': 'probability'})\n",
    "                     \n",
    "    return cv_val"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 36,
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stage(df_path, lgb_path, cb_path):\n",
    "    \n",
    "    print('Load Train Data.')\n",
    "    df = pd.read_csv(df_path)\n",
    "    print('\\nShape of Train Data: {}'.format(df.shape))\n",
    "    \n",
    "    y_df = np.array(df['target'])                        \n",
    "    df_ids = np.array(df.index)                     \n",
    "    df.drop(['ID_code', 'target'], axis=1, inplace=True)\n",
    "    \n",
    "    lgb_cv_result = np.zeros(df.shape[0])\n",
    "    cb_cv_result  = np.zeros(df.shape[0])\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    skf.get_n_splits(df_ids, y_df)\n",
    "    \n",
    "    print('\\nModel Fitting...')\n",
    "    for counter, ids in enumerate(skf.split(df_ids, y_df)):\n",
    "        print('\\nFold {}'.format(counter+1))\n",
    "        X_fit, y_fit = df.values[ids[0]], y_df[ids[0]]\n",
    "        X_val, y_val = df.values[ids[1]], y_df[ids[1]]\n",
    "    \n",
    "        print('LigthGBM')\n",
    "        lgb_cv_result[ids[1]] += fit_lgb(X_fit, y_fit, X_val, y_val, counter, lgb_path, name='lgb')\n",
    "        print('CatBoost')\n",
    "        cb_cv_result[ids[1]]  += fit_cb(X_fit,  y_fit, X_val, y_val, counter, cb_path,  name='cb')\n",
    "        \n",
    "        del X_fit, X_val, y_fit, y_val\n",
    "        gc.collect()\n",
    "    \n",
    "    auc_lgb  = round(roc_auc_score(y_df, lgb_cv_result),4)\n",
    "    auc_cb   = round(roc_auc_score(y_df, cb_cv_result), 4)\n",
    "    auc_mean_lgb_cb = round(roc_auc_score(y_df, (lgb_cv_result+cb_cv_result)/2), 4)\n",
    "    print('\\nLightGBM VAL AUC: {}'.format(auc_lgb))\n",
    "    print('Catboost VAL AUC: {}'.format(auc_cb))\n",
    "    print('Mean Catboost+LightGBM VAL AUC: {}'.format(auc_mean_lgb_cb))\n",
    "    \n",
    "    return 0\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 34,
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_stage(df_path, lgb_path, cb_path):\n",
    "    \n",
    "    print('Load Test Data.')\n",
    "    df = pd.read_csv(df_path)\n",
    "    print('\\nShape of Test Data: {}'.format(df.shape))\n",
    "    \n",
    "    df.drop(['ID_code'], axis=1, inplace=True)\n",
    "    \n",
    "    lgb_models = sorted(os.listdir(lgb_path))\n",
    "    cb_models  = sorted(os.listdir(cb_path))\n",
    "    \n",
    "    lgb_result = np.zeros(df.shape[0])\n",
    "    cb_result  = np.zeros(df.shape[0])\n",
    "    \n",
    "    print('\\nMake predictions...\\n')\n",
    "    \n",
    "    print('With LightGBM...')\n",
    "    for m_name in lgb_models:\n",
    "        #Load LightGBM Model\n",
    "        model = lgb.Booster(model_file='{}{}'.format(lgb_path, m_name))\n",
    "        lgb_result += model.predict(df.values)\n",
    "    \n",
    "    print('With CatBoost...')        \n",
    "    for m_name in cb_models:\n",
    "        #Load Catboost Model\n",
    "        model = cb.CatBoostClassifier()\n",
    "        model = model.load_model('{}{}'.format(cb_path, m_name), format = 'coreml')\n",
    "        cb_result += model.predict(df.values, prediction_type='Probability')[:,1]\n",
    "    \n",
    "    lgb_result /= len(lgb_models)\n",
    "    cb_result  /= len(cb_models)\n",
    "    \n",
    "    submission = pd.read_csv('./data/sample_submission.csv')\n",
    "    submission['target'] = ((lgb_result+cb_result)+cb_result)/3\n",
    "    submission.to_csv('lgb_cb2_starter_submission.csv', index=False)\n",
    "    submission['target'] = ((lgb_result+cb_result)+lgb_result)/3\n",
    "    submission.to_csv('lgb2_cb_starter_submission.csv', index=False)\n",
    "    submission['target'] = (lgb_result+cb_result)/2\n",
    "    submission.to_csv('lgb_cb_starter_submission.csv', index=False)\n",
    "    submission['target'] = lgb_result\n",
    "    submission.to_csv('lgb_starter_submission.csv', index=False)\n",
    "    submission['target'] = cb_result\n",
    "    submission.to_csv('cb_starter_submission.csv', index=False)\n",
    "    \n",
    "    return 0\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 37,
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Training Stage.\n",
      "\n",
      "Load Train Data.\n",
      "\n",
      "Shape of Train Data: (200000, 202)\n",
      "\n",
      "Model Fitting...\n",
      "\n",
      "Fold 1\n",
      "LigthGBM\n",
      "CatBoost\n",
      "\n",
      "Fold 2\n",
      "LigthGBM\n",
      "CatBoost\n",
      "\n",
      "Fold 3\n",
      "LigthGBM\n",
      "CatBoost\n",
      "\n",
      "Fold 4\n",
      "LigthGBM\n",
      "CatBoost\n",
      "\n",
      "Fold 5\n",
      "LigthGBM\n",
      "CatBoost\n",
      "\n",
      "LightGBM VAL AUC: 0.8881\n",
      "Catboost VAL AUC: 0.8998\n",
      "Mean Catboost+LightGBM VAL AUC: 0.8995\n",
=======
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
      "Prediction Stage.\n",
      "\n",
      "Load Test Data.\n",
      "\n",
      "Shape of Test Data: (200000, 201)\n",
      "\n",
      "Make predictions...\n",
      "\n",
      "With LightGBM...\n",
      "With CatBoost...\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    train_path = './data/train.csv'\n",
    "    test_path  = './data/test.csv'\n",
    "    \n",
    "    lgb_path = './lgb_models_stack/'\n",
    "    cb_path  = './cb_models_stack/'\n",
    "    \n",
    "    print('Training Stage.\\n')\n",
    "    train_stage(train_path, lgb_path, cb_path)\n",
    "    \n",
    "    print('Prediction Stage.\\n')\n",
    "    prediction_stage(test_path, lgb_path, cb_path)\n",
    "    \n",
    "    print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import pprint\n",
    "import joblib\n",
    "\n",
    "# Suppressing warnings because of skopt verbosity\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Our example dataset\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Hyperparameters distributions\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, mean_absolute_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Skopt functions\n",
    "from skopt import BayesSearchCV\n",
    "from skopt import gp_minimize # Bayesian optimization using Gaussian Processes\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.utils import use_named_args # decorator to convert a list of parameters to named arguments\n",
    "from skopt.callbacks import DeadlineStopper # Stop the optimization before running out of a fixed budget of time.\n",
    "from skopt.callbacks import VerboseCallback # Callback to control the verbosity\n",
    "from skopt.callbacks import DeltaXStopper # Stop the optimization If the last two positions at which the objective has been evaluated are less than delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_perf(optimizer, X, y, title, callbacks=None):\n",
    "    \"\"\"\n",
    "    A wrapper for measuring time and performances of different optmizers\n",
    "    \n",
    "    optimizer = a sklearn or a skopt optimizer\n",
    "    X = the training set \n",
    "    y = our target\n",
    "    title = a string label for the experiment\n",
    "    \"\"\"\n",
    "    start = time()\n",
    "    if callbacks:\n",
    "        optimizer.fit(X, y, callback=callbacks)\n",
    "    else:\n",
    "        optimizer.fit(X, y)\n",
    "    best_score = optimizer.best_score_\n",
    "    best_score_std = optimizer.cv_results_['std_test_score'][optimizer.best_index_]\n",
    "    best_params = optimizer.best_params_\n",
    "    print((title + \" took %.2f seconds,  candidates checked: %d, best CV score: %.3f \"\n",
    "           +u\"\\u00B1\"+\" %.3f\") % (time() - start, \n",
    "                                  len(optimizer.cv_results_['params']),\n",
    "                                  best_score,\n",
    "                                  best_score_std))    \n",
    "    print('Best parameters:')\n",
    "    pprint.pprint(best_params)\n",
    "    print()\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting average precision score into a scorer suitable for model selection\n",
    "avg_prec = make_scorer(average_precision_score, greater_is_better=True, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "\n",
    "# Setting a 5-fold stratified cross-validation (note: shuffle=True)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# A Scikit-learn GBM classifier\n",
    "clf = GradientBoostingClassifier(n_estimators=20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Train Data.\n",
      "\n",
      "Shape of Train Data: (200000, 202)\n"
     ]
    }
   ],
   "source": [
    "print('Load Train Data.')\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "print('\\nShape of Train Data: {}'.format(df.shape))\n",
    "\n",
    "y_df = np.array(df['target'])                        \n",
    "df_ids = np.array(df.index)                     \n",
    "df.drop(['ID_code', 'target'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GridSearchCV needs a predefined plan of the experiments\n",
    "# grid_search = GridSearchCV(clf, \n",
    "#                            param_grid={\"learning_rate\": [0.01, 1.0],\n",
    "#                                        \"n_estimators\": [10, 500],\n",
    "#                                        \"subsample\": [1.0, 0.5],\n",
    "#                                        \"min_samples_split\": [2, 10],\n",
    "#                                        \"min_samples_leaf\": [1, 10],\n",
    "#                                        \"max_features\": ['sqrt', 'log2', None]\n",
    "#                                        },\n",
    "#                            n_jobs=-1,\n",
    "#                            cv=skf,\n",
    "#                            scoring=avg_prec,\n",
    "#                            iid=False, # just return the average score across folds\n",
    "#                            return_train_score=False)\n",
    "\n",
    "# best_params = report_perf(grid_search, df, y_df,'GridSearchCV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RandomizedSearchCV needs the distribution of the experiments to be tested\n",
    "# # If you can provide the right distribution, the sampling will lead to faster and better results.\n",
    "\n",
    "# random_search = RandomizedSearchCV(clf, \n",
    "#                            param_distributions={\"learning_rate\": uniform(0.01, 1.0),\n",
    "#                                                 \"n_estimators\": randint(10, 500),\n",
    "#                                                 \"subsample\": uniform(0.5, 0.5),\n",
    "#                                                 \"min_samples_split\": randint(2, 10),\n",
    "#                                                 \"min_samples_leaf\": randint(1, 10),\n",
    "#                                                 \"max_features\": ['sqrt', 'log2', None]\n",
    "#                                        },\n",
    "#                                    n_iter=40,\n",
    "#                                    cv=skf,\n",
    "#                                    scoring=avg_prec,\n",
    "#                                    iid=False, # just return the average score across folds\n",
    "#                                    return_train_score=False,\n",
    "#                                    random_state=0,\n",
    "#                                    n_jobs=2,\n",
    "#                                   verbose=10)\n",
    "\n",
    "# best_params = report_perf(random_search, df, y_df, 'RandomizedSearchCV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed: 44.1min remaining: 66.2min\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   5 | elapsed: 44.3min remaining: 29.5min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed: 77.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed: 77.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed: 77.1min remaining: 115.6min\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   5 | elapsed: 77.1min remaining: 51.4min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed: 134.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed: 134.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:  3.2min remaining:  4.7min\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   5 | elapsed:  6.1min remaining:  4.1min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  6.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed: 210.0min remaining: 315.0min\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   5 | elapsed: 210.1min remaining: 140.1min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed: 224.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed: 224.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:   49.7s remaining:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   5 | elapsed:   49.9s remaining:   33.2s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  1.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:  9.9min remaining: 14.9min\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   5 | elapsed:  9.9min remaining:  6.6min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed: 16.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed: 16.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:  1.1min remaining:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   5 | elapsed:  1.1min remaining:   44.4s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  1.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed: 46.0min remaining: 69.0min\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   5 | elapsed: 46.1min remaining: 30.7min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed: 80.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed: 80.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed: 42.6min remaining: 63.9min\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   5 | elapsed: 42.6min remaining: 28.4min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed: 206.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed: 206.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:  9.0min remaining: 13.5min\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   5 | elapsed:  9.0min remaining:  6.0min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed: 15.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed: 15.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed: 33.0min remaining: 49.5min\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   5 | elapsed: 33.1min remaining: 22.1min\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(boosting_type='gbdt',\n",
    "                         class_weight='balanced',\n",
    "                         objective='binary',\n",
    "                         n_jobs=1,\n",
    "                         boost_from_average=True,\n",
    "                         verbose=0)\n",
    "\n",
    "search_spaces = {\n",
    "        'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "        'num_leaves': Integer(2, 200),\n",
    "        'max_depth': Integer(0, 200),\n",
    "        'min_child_samples': Integer(0, 200),\n",
    "        'max_bin': Integer(100, 4000),\n",
    "        'subsample': Real(0.01, 1.0, 'uniform'),\n",
    "        'subsample_freq': Integer(0, 10),\n",
    "        'colsample_bytree': Real(0.01, 1.0, 'uniform'),\n",
    "        'min_child_weight': Integer(0, 10),\n",
    "        'subsample_for_bin': Integer(100000, 400000),\n",
    "        'reg_lambda': Real(1e-9, 1000, 'log-uniform'),\n",
    "        'reg_alpha': Real(1e-9, 1.0, 'log-uniform'),\n",
    "        'scale_pos_weight': Real(1e-6, 500, 'log-uniform'),\n",
    "        'n_estimators': Integer(10, 10000)        \n",
    "        }\n",
    "\n",
    "opt = BayesSearchCV(clf,\n",
    "                    search_spaces,\n",
    "                    scoring=avg_prec,\n",
    "                    cv=skf,\n",
    "                    n_iter=40,\n",
    "                    n_jobs=4,\n",
    "                    return_train_score=False,\n",
    "                    refit=True,\n",
    "                    optimizer_kwargs={'base_estimator': 'GP'},\n",
    "                    random_state=22,\n",
    "                   verbose=10)\n",
    "    \n",
    "best_params = report_perf(opt, df, y_df,'LightGBM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CatBoostClassifier(loss_function='Logloss',\n",
    "                         verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces = {'iterations': Integer(10, 100),\n",
    "                 'depth': Integer(1, 8),\n",
    "                 'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "                 'random_strength': Real(1e-9, 10, 'log-uniform'),\n",
    "                 'bagging_temperature': Real(0.0, 1.0),\n",
    "                 'border_count': Integer(1, 255),\n",
    "                 'ctr_border_count': Integer(1, 255),\n",
    "                 'l2_leaf_reg': Integer(2, 30),\n",
    "                 'scale_pos_weight':Real(0.01, 1.0, 'uniform')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-bc26a3f1ef77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m best_params = report_perf(opt, df, y_df,'CatBoost', \n\u001b[0;32m     13\u001b[0m                           callbacks=[DeltaXStopper(0.001), \n\u001b[1;32m---> 14\u001b[1;33m                                      DeadlineStopper(60*5)])\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-934dbba0ae05>\u001b[0m in \u001b[0;36mreport_perf\u001b[1;34m(optimizer, X, y, title, callbacks)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, callback)\u001b[0m\n\u001b[0;32m    660\u001b[0m                 optim_result = self._step(\n\u001b[0;32m    661\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m                     \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_points_adjusted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    663\u001b[0m                 )\n\u001b[0;32m    664\u001b[0m                 \u001b[0mn_iter\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mn_points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m_step\u001b[1;34m(self, X, y, search_space, optimizer, groups, n_points)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[0mrefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[0;32m    401\u001b[0m                 \u001b[0merror_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             )\n\u001b[1;32m--> 403\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m             for train, test in cv_iter)\n\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval)\u001b[0m\n\u001b[0;32m   2181\u001b[0m         self._fit(X, y, cat_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0;32m   2182\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2183\u001b[1;33m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval)\n\u001b[0m\u001b[0;32m   2184\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval)\u001b[0m\n\u001b[0;32m   1087\u001b[0m         \u001b[0m_check_train_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1089\u001b[1;33m         \u001b[0mtrain_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_build_train_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1090\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_empty_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCatboostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X is empty.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_build_train_pool\u001b[1;34m(X, y, cat_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCatboostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         train_pool = Pool(X, y, cat_features=cat_features, pairs=pairs, weight=sample_weight, group_id=group_id,\n\u001b[1;32m--> 655\u001b[1;33m                           group_weight=group_weight, subgroup_id=subgroup_id, pairs_weight=pairs_weight, baseline=baseline)\n\u001b[0m\u001b[0;32m    656\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, cat_features, column_description, pairs, delimiter, has_header, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names, thread_count)\u001b[0m\n\u001b[0;32m    284\u001b[0m                         )\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_init\u001b[1;34m(self, data, label, cat_features, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names)\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36miteritems\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_item_cache'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = BayesSearchCV(clf,\n",
    "                    search_spaces,\n",
    "                    scoring=avg_prec,\n",
    "                    cv=skf,\n",
    "                    n_iter=40,\n",
    "                    n_jobs=1,  # use just 1 job with CatBoost in order to avoid segmentation fault\n",
    "                    return_train_score=False,\n",
    "                    refit=True,\n",
    "                    optimizer_kwargs={'base_estimator': 'GP'},\n",
    "                    random_state=22)\n",
    "\n",
    "best_params = report_perf(opt, df, y_df,'CatBoost', \n",
    "                          callbacks=[DeltaXStopper(0.001), \n",
    "                                     DeadlineStopper(60*5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 15.9min\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed: 47.4min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed: 66.8min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed: 91.0min\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed: 113.9min\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed: 144.1min\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed: 177.1min\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed: 212.9min\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed: 247.5min\n",
      "[Parallel(n_jobs=-1)]: Done 101 tasks      | elapsed: 291.8min\n",
      "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed: 334.1min\n",
      "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed: 384.2min\n",
      "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed: 429.7min\n",
      "[Parallel(n_jobs=-1)]: Done 169 tasks      | elapsed: 478.1min\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed: 533.1min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 561.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 33883.24 seconds,  candidates checked: 40, best CV score: 0.607 ± 0.010\n",
      "Best parameters:\n",
      "{'bagging_temperature': 0.9795867288127285,\n",
      " 'border_count': 255,\n",
      " 'ctr_border_count': 255,\n",
      " 'l2_leaf_reg': 30,\n",
      " 'learning_rate': 0.12872771895424406,\n",
      " 'random_strength': 3.1798317949397603}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomizedSearchCV needs the distribution of the experiments to be tested\n",
    "# If you can provide the right distribution, the sampling will lead to faster and better results.\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, \n",
    "                           param_distributions={\"learning_rate\": uniform(0.01, 1.0),\n",
    "                                                \"random_strength\":uniform(1e-9, 10),\n",
    "                                                'bagging_temperature': uniform(0.0, 1.0),\n",
    "                                                'border_count': [1, 255],\n",
    "                                                 'ctr_border_count': [1, 255],\n",
    "                                                'l2_leaf_reg': [2, 30]\n",
    "                                       },\n",
    "                                   n_iter=40,\n",
    "                                   n_jobs=-1,\n",
    "                                   cv=skf,\n",
    "                                   scoring=avg_prec,\n",
    "                                   iid=False, # just return the average score across folds\n",
    "                                   return_train_score=False,\n",
    "                                   random_state=0,\n",
    "                                  verbose=10)\n",
    "\n",
    "best_params = report_perf(random_search, df, y_df, 'RandomizedSearchCV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier(boosting_type='gbdt',\n",
    "                         verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] learning_rate=0.5488135039273248, max_bin=255, min_data_in_leaf=1, num_leaves=60, sub_feature=0.8579456176227568 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[CV]  learning_rate=0.5488135039273248, max_bin=255, min_data_in_leaf=1, num_leaves=60, sub_feature=0.8579456176227568, score=0.3407890675078338, total=  12.8s\n",
=======
      "[CV]  learning_rate=0.5488135039273248, max_bin=255, min_data_in_leaf=1, num_leaves=60, sub_feature=0.8579456176227568, score=0.3407890675078338, total=  22.8s\n",
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
      "[CV] learning_rate=0.5488135039273248, max_bin=255, min_data_in_leaf=1, num_leaves=60, sub_feature=0.8579456176227568 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.8s remaining:    0.0s\n"
=======
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   22.9s remaining:    0.0s\n"
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[CV]  learning_rate=0.5488135039273248, max_bin=255, min_data_in_leaf=1, num_leaves=60, sub_feature=0.8579456176227568, score=0.3317179587764757, total=  15.2s\n",
=======
      "[CV]  learning_rate=0.5488135039273248, max_bin=255, min_data_in_leaf=1, num_leaves=60, sub_feature=0.8579456176227568, score=0.3315062976956401, total=  23.6s\n",
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
      "[CV] learning_rate=0.5488135039273248, max_bin=255, min_data_in_leaf=1, num_leaves=60, sub_feature=0.8579456176227568 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   28.1s remaining:    0.0s\n"
=======
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   46.7s remaining:    0.0s\n"
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[CV]  learning_rate=0.5488135039273248, max_bin=255, min_data_in_leaf=1, num_leaves=60, sub_feature=0.8579456176227568, score=0.3377802398072303, total=  14.1s\n",
=======
      "[CV]  learning_rate=0.5488135039273248, max_bin=255, min_data_in_leaf=1, num_leaves=60, sub_feature=0.8579456176227568, score=0.33766532494513074, total=  20.4s\n",
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
      "[CV] learning_rate=0.5488135039273248, max_bin=255, min_data_in_leaf=1, num_leaves=60, sub_feature=0.8579456176227568 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   42.2s remaining:    0.0s\n"
=======
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.1min remaining:    0.0s\n"
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[CV]  learning_rate=0.5488135039273248, max_bin=255, min_data_in_leaf=1, num_leaves=60, sub_feature=0.8579456176227568, score=0.34683421644709655, total=  14.7s\n",
=======
      "[CV]  learning_rate=0.5488135039273248, max_bin=255, min_data_in_leaf=1, num_leaves=60, sub_feature=0.8579456176227568, score=0.34683421644709655, total=  20.8s\n",
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
      "[CV] learning_rate=0.5488135039273248, max_bin=255, min_data_in_leaf=1, num_leaves=60, sub_feature=0.8579456176227568 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   57.0s remaining:    0.0s\n"
=======
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.5min remaining:    0.0s\n"
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[CV]  learning_rate=0.5488135039273248, max_bin=255, min_data_in_leaf=1, num_leaves=60, sub_feature=0.8579456176227568, score=0.3335237699965039, total=  14.1s\n",
=======
      "[CV]  learning_rate=0.5488135039273248, max_bin=255, min_data_in_leaf=1, num_leaves=60, sub_feature=0.8579456176227568, score=0.3335237699965039, total=  19.4s\n",
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
      "[CV] learning_rate=0.8472517387841254, max_bin=255, min_data_in_leaf=60, num_leaves=10, sub_feature=0.4375872112626925 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.2min remaining:    0.0s\n"
=======
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.8min remaining:    0.0s\n"
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[CV]  learning_rate=0.8472517387841254, max_bin=255, min_data_in_leaf=60, num_leaves=10, sub_feature=0.4375872112626925, score=0.48895203647345087, total=   6.4s\n",
=======
      "[CV]  learning_rate=0.8472517387841254, max_bin=255, min_data_in_leaf=60, num_leaves=10, sub_feature=0.4375872112626925, score=0.48895203647345087, total=   8.2s\n",
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
      "[CV] learning_rate=0.8472517387841254, max_bin=255, min_data_in_leaf=60, num_leaves=10, sub_feature=0.4375872112626925 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.3min remaining:    0.0s\n"
=======
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.9min remaining:    0.0s\n"
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[CV]  learning_rate=0.8472517387841254, max_bin=255, min_data_in_leaf=60, num_leaves=10, sub_feature=0.4375872112626925, score=0.48700233114497243, total=   6.2s\n",
=======
      "[CV]  learning_rate=0.8472517387841254, max_bin=255, min_data_in_leaf=60, num_leaves=10, sub_feature=0.4375872112626925, score=0.48700233114497243, total=   8.2s\n",
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
      "[CV] learning_rate=0.8472517387841254, max_bin=255, min_data_in_leaf=60, num_leaves=10, sub_feature=0.4375872112626925 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.4min remaining:    0.0s\n"
=======
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  2.1min remaining:    0.0s\n"
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[CV]  learning_rate=0.8472517387841254, max_bin=255, min_data_in_leaf=60, num_leaves=10, sub_feature=0.4375872112626925, score=0.5089244186036075, total=   6.4s\n",
=======
      "[CV]  learning_rate=0.8472517387841254, max_bin=255, min_data_in_leaf=60, num_leaves=10, sub_feature=0.4375872112626925, score=0.5089244186036075, total=   8.2s\n",
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
      "[CV] learning_rate=0.8472517387841254, max_bin=255, min_data_in_leaf=60, num_leaves=10, sub_feature=0.4375872112626925 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.5min remaining:    0.0s\n"
=======
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  2.2min remaining:    0.0s\n"
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[CV]  learning_rate=0.8472517387841254, max_bin=255, min_data_in_leaf=60, num_leaves=10, sub_feature=0.4375872112626925, score=0.5098401178150745, total=   6.8s\n",
=======
      "[CV]  learning_rate=0.8472517387841254, max_bin=255, min_data_in_leaf=60, num_leaves=10, sub_feature=0.4375872112626925, score=0.5098401178150745, total=   8.5s\n",
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
      "[CV] learning_rate=0.8472517387841254, max_bin=255, min_data_in_leaf=60, num_leaves=10, sub_feature=0.4375872112626925 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.6min remaining:    0.0s\n"
=======
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  2.4min remaining:    0.0s\n"
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[CV]  learning_rate=0.8472517387841254, max_bin=255, min_data_in_leaf=60, num_leaves=10, sub_feature=0.4375872112626925, score=0.518560507499517, total=   6.5s\n",
=======
      "[CV]  learning_rate=0.8472517387841254, max_bin=255, min_data_in_leaf=60, num_leaves=10, sub_feature=0.4375872112626925, score=0.518560507499517, total=   9.1s\n",
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
      "[CV] learning_rate=0.8917730007820798, max_bin=2, min_data_in_leaf=1, num_leaves=10, sub_feature=0.47766511732134986 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# RandomizedSearchCV needs the distribution of the experiments to be tested\n",
    "# If you can provide the right distribution, the sampling will lead to faster and better results.\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, \n",
    "                           param_distributions={\"num_leaves\": [10, 60],\n",
    "                                                \"min_data_in_leaf\":[1, 60],\n",
    "                                                'max_bin': [2, 255],\n",
    "                                                 'learning_rate': uniform(0.0, 1.0),\n",
    "                                                'sub_feature': uniform(0.0, 1.0)\n",
    "                                       },\n",
    "                                   n_iter=40,\n",
    "                                   cv=skf,\n",
    "                                   scoring=avg_prec,\n",
    "                                   iid=False, # just return the average score across folds\n",
    "                                   return_train_score=False,\n",
    "                                   random_state=0,\n",
    "                                  verbose=10)\n",
    "\n",
    "best_params = report_perf(random_search, df, y_df, 'RandomizedSearchCV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.6.4"
=======
   "version": "3.6.8"
>>>>>>> 69e1c9054d387bcf995cdffd7385140b601aaf30
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
